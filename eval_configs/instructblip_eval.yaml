model:
  arch: blip2_vicuna_instruct
  model_type: vicuna7b
  max_txt_len: 512
  # end_sym: "###"
  # low_resource: True
  # prompt_template: '###Human: {} ###Assistant: '
  merged_ckpt: "/data3/fyx/instructblip-vicuna-7b"


datasets:
  cc_sbu_align:
    vis_processor:
      train:
        name: "blip2_image_eval"
        image_size: 224
    text_processor:
      train:
        name: "blip_caption"

run:
  task: image_text_pretrain
  seed: 42
